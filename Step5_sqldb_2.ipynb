{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import sqlalchemy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "import os\n",
    "from glob import glob\n",
    "import pickle\n",
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open (r'data/spotify_ids.pkl', 'rb') as f:\n",
    "    spotify_ids = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connect to music sqlite3 database \n",
    "conn = sqlite3.connect('music.db')\n",
    "c = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join Spotify track ids to Genius lyrics data\n",
    "PATH = \"data/lyrics/\"\n",
    "EXT = \"*.txt\"\n",
    "\n",
    "lyric_txts = [file\n",
    "             for path, subdir, files in os.walk(PATH)\n",
    "             for file in glob(os.path.join(path, EXT))]\n",
    "\n",
    "lyrics_dict = {}   # dict to store {song: lyrics} values\n",
    "\n",
    "for fname in lyric_txts:\n",
    "    fname_spl = fname.split('.txt')[0]\n",
    "    fname_spl2 = fname_spl.split('\\\\')\n",
    "    song = fname_spl2[1]\n",
    "    \n",
    "    with open(fname, 'r', encoding='utf8') as f:\n",
    "        lyrics_dict[song] = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lyrics_df = (pd.DataFrame.from_dict(lyrics_dict, orient='index')).reset_index().rename(index = str, columns = {'index': 'song_name', 0: 'text'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df = pd.DataFrame(spotify_ids).rename(columns = {0: 'song_name_orig', 1: 'song_name', 2: 'spotify_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "spotify_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge spotify ids df and lyrics df\n",
    "merged = lyrics_df.merge(spotify_df, how='left', on='song_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to sqlite db\n",
    "merged.to_sql('lyrics', con=conn, index=False, if_exists='replace')\n",
    "conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add BB100 data to sqlite db\n",
    "\n",
    "# find all csv files stored in 'data' folder\n",
    "bb100_dask = dd.read_csv('data/*.csv')  # Dask can read in multiple csvs to a single df\n",
    "bb100_df = bb100_dask.compute()  # convert Dask df to Pandas df\n",
    "\n",
    "# add to sqlite db\n",
    "bb100_df.to_sql('bb100', con=conn, index=False, if_exists='replace')\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('ckids': conda)",
   "language": "python",
   "name": "python37664bitckidscondaeba5e997e95d433391cca1cee29345d7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}